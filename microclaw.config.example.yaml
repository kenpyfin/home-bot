# MicroClaw configuration (legacy YAML format)
# Use .env instead: cp .env.example .env and run microclaw setup.

# Telegram bot token from @BotFather
telegram_bot_token: ""
# Bot username without @
bot_username: ""

# LLM provider (anthropic, ollama, openai, openrouter, deepseek, google, etc.)
llm_provider: "anthropic"
# API key for LLM provider
api_key: ""
# Model name (leave empty for provider default)
model: ""
# Custom base URL (optional, null to use provider default)
# llm_base_url: null

# Max tokens per response
max_tokens: 8192
# Max tool loop iterations per message
max_tool_iterations: 100
# Chat history context size
max_history_messages: 50
# Maximum inbound Telegram document size in MB
max_document_size_mb: 100
# Workspace directory (optional). Single root for runtime, skills, and tool workspace.
# Layout: workspace_dir/runtime, workspace_dir/skills, workspace_dir/shared. Copy this folder to migrate.
# Omit or leave empty: default ./workspace (or MICROCLAW_WORKSPACE_DIR in Docker).
# Default default to copy ./workspace to the container
# workspace_dir: "./workspace"
# IANA timezone for scheduling (e.g. "US/Eastern", "Europe/London")
timezone: "UTC"

# Orchestrator (plan-first architecture). Runs planning step before main agent loop.
# orchestrator_enabled: true
# orchestrator_model: ""   # Optional: faster/cheaper model for planning; if empty, use main model

# OpenAI API key for voice transcription via Whisper (optional)
# openai_api_key: ""

# Session management
max_session_messages: 40
compact_keep_recent: 20

# Telegram group allowlist (empty = allow all groups)
# allowed_groups: []

# Control chats can operate across chats (send_message/schedule/export/tiered memory).
# Non-control chats are restricted to their own chat_id.
# control_chat_ids: []

# WhatsApp Cloud API (optional)
# whatsapp_access_token: ""
# whatsapp_phone_number_id: ""
# whatsapp_verify_token: ""
# whatsapp_webhook_port: 8080

# Discord (optional)
# discord_bot_token: ""
# discord_allowed_channels: []

# Local web UI (optional)
# Enable built-in local web chat + config panel
web_enabled: true
# Bind address for local web UI
web_host: "127.0.0.1"
# Port for local web UI
web_port: 10961
# Optional bearer token for Web API/UI.
# If set, requests must send Authorization: Bearer <token>
# web_auth_token: ""
# Max in-flight requests per session
web_max_inflight_per_session: 2
# Max requests allowed per session in rate window
web_max_requests_per_window: 8
# Rate limit window length (seconds)
web_rate_window_seconds: 10
# Buffered SSE event history per run for replay
web_run_history_limit: 512
# Idle cleanup TTL for web session quota/locks (seconds)
web_session_idle_ttl_seconds: 300

# Browser automation uses the agent-browser CLI (npm install -g agent-browser;
# agent-browser install). If agent-browser is not on PATH (e.g. when run as a service),
# set the full path here. Tilde is expanded (e.g. ~/.local/bin/agent-browser).
# agent_browser_path: "~/.local/bin/agent-browser"

# Cursor CLI agent (cursor_agent tool). Install: curl https://cursor.com/install -fsS | bash
# Path to cursor-agent binary (default: cursor-agent, or cursor-agent.cmd on Windows)
# cursor_agent_cli_path: "cursor-agent"
# Model for cursor-agent (e.g. gpt-5). Leave empty to omit --model (use Cursor default / auto)
# cursor_agent_model: ""
# Timeout in seconds for cursor-agent runs (default: 600)
# cursor_agent_timeout_secs: 600


# ORIGIN Obsidian vault / vector DB (optional). Paths are relative to workspace_dir.
# When set, these values are injected into the system prompt so the bot knows vault paths.
# vault:
#   origin_vault_path: "shared/ORIGIN"
#   vector_db_path: "shared/vault_db"
#   embedding_server_url: "http://127.0.0.1:8080"
#   vault_search_command: 'python3 query_vault.py "{query}"'
#   vault_index_command: "python3 index_vault.py"
#   principles_path: "AGENTS.md"   # override if principles live inside vault (e.g. "shared/ORIGIN/AGENTS.md")
